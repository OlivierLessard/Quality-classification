from __future__ import print_function
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
import os
from keras.applications.resnet50 import ResNet50, preprocess_input
from keras.applications.densenet import DenseNet169
from build_model import resnet_v2, resnet_v1, build_finetune_model
from save_model import save_model
from load_data import create_training_data
from keras.layers import Input
import pickle
import matplotlib
import matplotlib.pyplot as plt
from keras.callbacks import TensorBoard
import time
import sklearn
from sklearn.utils.multiclass import unique_labels
from keras.models import load_model
from sklearn.metrics import confusion_matrix
import itertools


# Training parameters
num_classes = 2
img_size = 80
CATEGORIES = ["Dog", "Cat"]

# AUC
# google colab , save model in google drive and load it
# !python train_model


def train_model(x_train, y_train, x_test, y_test, x_cv, y_cv):
    # training parameters
    batch_size = 32
    epochs = 50
    data_augmentation = True

    # Prepare ModelCheckpoint callback
    save_dir = os.path.join(os.getcwd(), 'saved_models')
    model_name = 'weights.best.hdf5'
    if not os.path.isdir(save_dir):
        os.makedirs(save_dir)
    filepath = os.path.join(save_dir, model_name)
    checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_accuracy', mode=max, verbose=1, save_best_only=True)

    NAME = "denseNet-{}".format(int(time.time()))
    tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))    # use tensorboard --logdir=logs/ on terminal

    lr_reducer = ReduceLROnPlateau(factor=0.5, monitor='val_accuracy', mode=max, cooldown=0, patience=5, min_lr=0.5e-6)

    earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, verbose=0, mode='auto',
                                  baseline=None, restore_best_weights=False)
    callbacks = [checkpoint, lr_reducer, tensorboard, earlystopping]

    # Run training, with or without data augmentation.
    if not data_augmentation:
        print('Not using data augmentation.')
        model.fit(x_train, y_train,
                  batch_size=batch_size,
                  epochs=epochs,
                  validation_data=(x_test, y_test),
                  shuffle=True,
                  callbacks=callbacks)
    else:
        # meaningfull
        print('Using real-time data augmentation.')
        # This will do preprocessing and realtime data augmentation:
        datagen = ImageDataGenerator(
            # set input mean to 0 over the dataset
            featurewise_center=False,
            # set each sample mean to 0
            samplewise_center=False,
            # divide inputs by std of dataset
            featurewise_std_normalization=False,
            # divide each input by its std
            samplewise_std_normalization=False,
            # apply ZCA whitening
            zca_whitening=False,
            # epsilon for ZCA whitening
            zca_epsilon=1e-06,
            # randomly rotate images in the range (deg 0 to 180)
            rotation_range=5,
            # randomly shift images horizontally
            width_shift_range=0.1,
            # randomly shift images vertically
            height_shift_range=0.1,
            # set range for random shear
            shear_range=0.,
            # set range for random zoom
            zoom_range=0.,
            # set range for random channel shifts
            channel_shift_range=0.,
            # set mode for filling points outside the input boundaries
            fill_mode='nearest',
            # value used for fill_mode = "constant"
            cval=0.,
            # randomly flip images
            horizontal_flip=False,
            # randomly flip images
            vertical_flip=False,
            # set rescaling factor (applied before any other transformation)
            rescale=None,
            # set function that will be applied on each input
            preprocessing_function=None,
            # image data format, either "channels_first" or "channels_last"
            data_format=None,
            # fraction of images reserved for validation (strictly between 0 and 1)
            validation_split=0.0)

        # Compute quantities required for featurewise normalization
        # (std, mean, and principal components if ZCA whitening is applied).
        datagen.fit(x_train)

    # Fit the model on the batches generated by datagen.flow().
    history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size), validation_data=(x_cv, y_cv),
                                  epochs=epochs, verbose=1, workers=4, callbacks=callbacks)

    return history, model


def plot_confusion_matrix(y_true, y_pred, classes,
                          normalize=False,
                          title=None,
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    if not title:
        if normalize:
            title = 'Normalized confusion matrix'
        else:
            title = 'Confusion matrix, without normalization'

    # Compute confusion matrix
    cm = confusion_matrix(y_true, y_pred)
    # Only use the labels that appear in the data
    #classes = classes[unique_labels(y_true, y_pred)]
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    fig, ax = plt.subplots()
    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)
    ax.figure.colorbar(im, ax=ax)
    # We want to show all ticks...
    ax.set(xticks=np.arange(cm.shape[1]),
           yticks=np.arange(cm.shape[0]),
           # ... and label them with the respective list entries
           xticklabels=classes, yticklabels=classes,
           title=title,
           ylabel='True label',
           xlabel='Predicted label')

    # Rotate the tick labels and set their alignment.
    plt.setp(ax.get_xticklabels(), rotation=45, ha="right",
             rotation_mode="anchor")

    # Loop over data dimensions and create text annotations.
    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            ax.text(j, i, format(cm[i, j], fmt),
                    ha="center", va="center",
                    color="white" if cm[i, j] > thresh else "black")
    plt.ylim([-0.5, 1.5]) # To fix the size limitation
    fig.tight_layout()

    return ax


def test_model():
    scores = model.evaluate(x_test, y_test, verbose=1)
    print('Test loss:', scores[0])
    print('Test accuracy:', scores[1])

    # confusion matrix
    y_prediction = model.predict(x_test, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10,
                                 workers=1, use_multiprocessing=False)

    np.set_printoptions(precision=2)

    cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_prediction, axis=1))

    # Plot normalized confusion matrix
    plot_confusion_matrix(np.argmax(y_test, axis=1), np.argmax(y_prediction, axis=1), classes=CATEGORIES, normalize=True,
                         title='Normalized confusion matrix')

    plt.show()
    plt.savefig("confusion matrix")

    # f1 score
    f1 = sklearn.metrics.f1_score(np.argmax(y_test, axis=1), np.argmax(y_prediction, axis=1), average='micro')
    print("The f1 score is : ", f1)
    pickle_out = open("f1.pickle", "wb")
    pickle.dump(f1, pickle_out)
    pickle_out.close()


# get the data
training_data = []
x_train = []
y_train = []
x_cv = []
y_cv = []
x_test = []
y_test = []
try:    # load saved data
    with open('x_test.pickle', 'rb') as data:
        x_test = pickle.load(data)
        data.close()
    with open('x_train.pickle', 'rb') as data:
        x_train = pickle.load(data)
        data.close()
    with open('x_cv.pickle', 'rb') as data:
        x_cv = pickle.load(data)
        data.close()
    with open('y_test.pickle', 'rb') as data:
        y_test = pickle.load(data)
        data.close()
    with open('y_train.pickle', 'rb') as data:
        y_train = pickle.load(data)
        data.close()
    with open('y_cv.pickle', 'rb') as data:
        y_cv = pickle.load(data)
        data.close()
except Exception as e:  # create the data
    x_train, y_train, x_cv, y_cv, x_test, y_test = create_training_data(x_train, y_train, x_cv, y_cv, x_test, y_test,
                                                                        training_data, num_classes, img_size, CATEGORIES)
input_shape = x_train.shape[1:]

model = load_model('my_model')
test_model()

# Define the model
base_model = DenseNet169(weights='imagenet', include_top=False, input_shape=input_shape)
model = build_finetune_model(base_model, num_classes=num_classes)
model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])
model.summary()

# train with all the specifications
history, model = train_model(x_train, y_train, x_test, y_test, x_cv, y_cv)

# test and plot metrics
test_model()

# save acc, loss, plots
save_model(model, history)
